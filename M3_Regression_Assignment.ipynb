{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efaf795",
   "metadata": {},
   "source": [
    "# Theory Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5363d1e",
   "metadata": {},
   "source": [
    "**1. What is Simple Linear Regression**\n",
    "\n",
    "Simple Linear Regression is a statistical method that models the relationship between a dependent variable and a single independent variable using a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556b21f9",
   "metadata": {},
   "source": [
    "**2. What are the key assumptions of Simple Linear Regression**\n",
    "\n",
    "Key assumptions: linearity, independence, homoscedasticity (constant variance), normality of residuals, no multicollinearity (not relevant in simple regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ac5eb",
   "metadata": {},
   "source": [
    "**3. What does the coefficient m represent in the equation Y=mX+c**\n",
    "\n",
    "The coefficient *m* represents the slope, i.e., the change in Y for a one-unit increase in X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3f829f",
   "metadata": {},
   "source": [
    "**4. What does the intercept c represent in the equation Y=mX+c**\n",
    "\n",
    "The intercept *c* represents the value of Y when X = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f284f",
   "metadata": {},
   "source": [
    "**5. How do we calculate the slope m in Simple Linear Regression**\n",
    "\n",
    "Slope m is calculated as: m = Σ((Xi - X̄)(Yi - Ȳ)) / Σ((Xi - X̄)²)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cb4d5",
   "metadata": {},
   "source": [
    "**6. What is the purpose of the least squares method in Simple Linear Regression**\n",
    "\n",
    "Least squares minimizes the sum of squared residuals (errors) to find the best-fitting line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3871b0",
   "metadata": {},
   "source": [
    "**7. How is the coefficient of determination (R²) interpreted in Simple Linear Regression**\n",
    "\n",
    "R² measures the proportion of variance in Y explained by X (values range between 0 and 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa6903",
   "metadata": {},
   "source": [
    "**8. What is Multiple Linear Regression**\n",
    "\n",
    "Multiple Linear Regression models the relationship between a dependent variable and multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c35a927",
   "metadata": {},
   "source": [
    "**9. What is the main difference between Simple and Multiple Linear Regression**\n",
    "\n",
    "Simple regression uses one independent variable; multiple regression uses two or more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d116d2f",
   "metadata": {},
   "source": [
    "**10. What are the key assumptions of Multiple Linear Regression**\n",
    "\n",
    "Key assumptions: linearity, independence, homoscedasticity, normality of residuals, no multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb5110",
   "metadata": {},
   "source": [
    "**11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model**\n",
    "\n",
    "Heteroscedasticity means non-constant variance of errors. It can lead to biased standard errors and unreliable hypothesis tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0462d",
   "metadata": {},
   "source": [
    "**12. How can you improve a Multiple Linear Regression model with high multicollinearity**\n",
    "\n",
    "Use techniques like removing/reducing correlated predictors, applying PCA, or regularization (Ridge/Lasso)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285b78de",
   "metadata": {},
   "source": [
    "**13. What are some common techniques for transforming categorical variables for use in regression models**\n",
    "\n",
    "Techniques: one-hot encoding, label encoding, target encoding, dummy variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e8a42",
   "metadata": {},
   "source": [
    "**14. What is the role of interaction terms in Multiple Linear Regression**\n",
    "\n",
    "Interaction terms capture combined effects of two or more variables (e.g., X1*X2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835499d",
   "metadata": {},
   "source": [
    "**15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression**\n",
    "\n",
    "In simple regression, intercept is Y when X=0. In multiple regression, it is Y when all X=0 (may not always be meaningful)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88458bc9",
   "metadata": {},
   "source": [
    "**16. What is the significance of the slope in regression analysis, and how does it affect predictions**\n",
    "\n",
    "Slope shows the strength and direction of the relationship. A positive slope means Y increases as X increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e103605",
   "metadata": {},
   "source": [
    "**17. How does the intercept in a regression model provide context for the relationship between variables**\n",
    "\n",
    "The intercept provides a baseline reference point for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd1bcc2",
   "metadata": {},
   "source": [
    "**18. What are the limitations of using R² as a sole measure of model performance**\n",
    "\n",
    "Limitations: R² alone cannot assess model fit; it increases with more predictors even if they add no value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1b7c25",
   "metadata": {},
   "source": [
    "**19. How would you interpret a large standard error for a regression coefficient**\n",
    "\n",
    "A large standard error suggests the coefficient estimate is not precise and may be unreliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96509167",
   "metadata": {},
   "source": [
    "**20. How can heteroscedasticity be identified in residual plots, and why is it important to address it**\n",
    "\n",
    "Heteroscedasticity appears as a funnel shape in residual plots. It must be addressed to ensure valid inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53bc026",
   "metadata": {},
   "source": [
    "**21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²**\n",
    "\n",
    "High R² but low adjusted R² means that some predictors add noise rather than explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad95fba",
   "metadata": {},
   "source": [
    "**22. Why is it important to scale variables in Multiple Linear Regression**\n",
    "\n",
    "Scaling ensures fair comparison among predictors, especially important for gradient descent and regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71710b03",
   "metadata": {},
   "source": [
    "**23. What is polynomial regression**\n",
    "\n",
    "Polynomial regression models non-linear relationships by including powers of independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b08db3",
   "metadata": {},
   "source": [
    "**24. How does polynomial regression differ from linear regression**\n",
    "\n",
    "Linear regression fits straight lines, polynomial regression fits curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5e58c",
   "metadata": {},
   "source": [
    "**25. When is polynomial regression used**\n",
    "\n",
    "It is used when data shows a curved relationship rather than a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d44088",
   "metadata": {},
   "source": [
    "**26. What is the general equation for polynomial regression**\n",
    "\n",
    "General equation: Y = β0 + β1X + β2X² + ... + βnX^n + ε."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0e3d2",
   "metadata": {},
   "source": [
    "**27. Can polynomial regression be applied to multiple variables**\n",
    "\n",
    "Yes, polynomial regression can be extended to multiple predictors with polynomial terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3dabb7",
   "metadata": {},
   "source": [
    "**28. What are the limitations of polynomial regression**\n",
    "\n",
    "Limitations: risk of overfitting, sensitive to outliers, complex interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f43069",
   "metadata": {},
   "source": [
    "**29. What methods can be used to evaluate model fit when selecting the degree of a polynomial**\n",
    "\n",
    "Use cross-validation, adjusted R², or information criteria (AIC/BIC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3be0d4",
   "metadata": {},
   "source": [
    "**30. Why is visualization important in polynomial regression**\n",
    "\n",
    "Visualization helps detect underfitting/overfitting and interpret polynomial curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc59b9e7",
   "metadata": {},
   "source": [
    "**31. How is polynomial regression implemented in Python?**\n",
    "\n",
    "Implemented in Python using libraries like scikit-learn (PolynomialFeatures + LinearRegression)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88304f24",
   "metadata": {},
   "source": [
    "# ------------------------------ Thank You ----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efec44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
